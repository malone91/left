mysql主备一致
因为 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。
其中 io_thread 负责与主库建立连接。
主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
sql_thread 读取中转日志，解析出日志里的命令，并执行。
这里需要说明，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂且不展开。

1、binlog格式为statement时，binlog记录的就是SQL的原文

mysql> delete from t /*comment*/  where a>=4 and t_modified<='2018-11-10' limit 1;
由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：
在主库执行这条 SQL 语句的时候，用的是索引 a；
而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。

2、当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，
这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。

binlog的mixed格式
因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
但 row 格式的缺点是，很占空间。
比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。
但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。
这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。
所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。
mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。

show global variables binlog_format：row

数据恢复：
因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。
你至少应该把 binlog 的格式设置为 mixed。比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；
而如果执行的语句去掉 limit 1，就会记录为 statement 格式。
当然我要说的是，现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，我来给你举一个可以直接看出来的好处：恢复数据。


mysql> insert into t values(10,10, now());
如果我们把 binlog 格式设置为 mixed，你觉得 MySQL 会把它记录为 row 格式还是 statement 格式呢？
答案是statement模式 ：原来 binlog 在记录 event 的时候，多记了一条命令：SET TIMESTAMP=1546103491。它用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间。
我之前看过有人在重放 binlog 数据的时候，是这么做的：
用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。
你现在知道了，这个方法是有风险的。因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的。

解析binlog 用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：
mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;

双 M 结构和 M-S 结构，其实区别只是多了一条线，即：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。
按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；
传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。
所以，死循环在这里就断掉了。

binlog是高可用的基础
binlog 在 MySQL 的各种高可用方案上扮演了重要角色。今天介绍的可以说是所有 MySQL 高可用方案的基础。
在这之上演化出了诸如多节点、半同步、MySQL group replication 等相对复杂的方案。

 show slave status
 它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。

 主备系统时间延迟和relay log耗时
 备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。
 如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。
 需要说明的是，在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。
 也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。
 所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。

主从延迟来源：
 面试： 不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。
 大事务这种情况很好理解。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。

 大事务：delete很多行，大表 DDL
 控制每个事务删除的数据量，分成多次删除。

主从延迟来源：

    1、大事务
    2、有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。
        一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。
        或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。
        其实我们都知道，更新请求对 IOPS 的压力，在主库和备库上是无差别的。
        所以，做这种部署时，一般都会将备库设置为“非双 1”的模式。
        但实际上，更新过程中也会触发大量的读操作。所以，当备库主机上的多个备库都在争抢资源的时候，就可能会导致主备延迟了。
        做了对称部署以后，还可能会有延迟：备库的压力大。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。
            或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。


        备库压力大：
        一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
        通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。
        其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。
        而从库，就很适合用来做备份。备注：这里需要说明一下，从库和备库在概念上其实差不多。
        在我们这个专栏里，为了方便描述，我把会在 HA 过程中被选成新主库的，称为备库，其他的称为从库。

主从延迟大于1秒就不行

 innodb_thread_concurrency 参数的目的是，控制 InnoDB 的并发线程上限。
 也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。

 我把 innodb_thread_concurrency 设置成 3，表示 InnoDB 只允许 3 个线程并行执行。
 而在我们的例子中，前三个 session 中的 sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大查询。
 你看到了， session D 里面，select 1 是能执行成功的，但是查询表 t 的语句会被堵住。
 也就是说，如果这时候我们用 select 1 来检测实例是否正常的话，是检测不出问题的。

并发查询数 innodb_thread_concurrency
 公司测试库为0
 在 InnoDB 中，innodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。
 但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。
 所以，通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。
 这时，你一定会有疑问，并发线程上限数设置为 128 够干啥，线上的并发连接数动不动就上千了。
 产生这个疑问的原因，是搞混了并发连接和并发查询。

并发连接查询 max_connections  MySQL: ERROR 1040: Too many connections”
Max_used_connections
 并发连接和并发查询，并不是同一个概念。
 你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。
 而“当前正在执行”的语句，才是我们所说的并发查询。
 并发连接数达到几千个影响并不大，就是多占一些内存而已。
 我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。
 这也是为什么我们需要设置 innodb_thread_concurrency 参数的原因。

 死锁：
 然后，你可能还会想起我们在第 7 篇文章中讲到的热点更新和死锁检测的时候，如果把 innodb_thread_concurrency 设置为 128 的话，
 那么出现同一行热点更新的问题时，是不是很快就把 128 消耗完了，这样整个系统是不是就挂了呢？
 实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。MySQL 这样设计是非常有意义的。
 因为，进入锁等待的线程已经不吃 CPU 了；更重要的是，必须这么设计，才能避免整个系统锁死。

 InnoDB 在设计时，遇到进程进入锁等待的情况时，将并发线程的计数减 1 的设计，是合理而且是必要的。

 为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。
 一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：
mysql> select * from mysql.health_check;

mysql> update mysql.health_check set t_modified=now();

当主备双M架构时，server_id重复的问题
mysql> CREATE TABLE `health_check` (
  `id` int(11) NOT NULL,
  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

/* 检测命令 */
insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();

SELECT @@server_id

在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id，表示终止这个线程中正在执行的语句；
一个是 kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。

不知道你在使用 MySQL 的时候，有没有遇到过这样的现象：使用了 kill 命令，却没能断开这个连接。
再执行 show processlist 命令，看到这条语句的 Command 列显示的是 Killed。

当对一个表做增删改查操作时，会在表上加 MDL 读锁。
所以，session B 虽然处于 blocked 状态，但还是拿着一个 MDL 读锁的。如果线程被 kill 的时候，就直接终止，那之后这个 MDL 读锁就没机会被释放了。

kill 并不是马上停止的意思，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。
其实，这跟 Linux 的 kill 命令类似，kill -N pid 并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑。
只是对于 MySQL 的 kill 命令来说，不需要传信号量参数，就只有“停止”这个命令。实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：
把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；
给 session B 的执行线程发一个信号。

show processlist
id       #ID标识，要kill一个语句的时候很有用
command  #连接状态，一般是休眠（sleep），查询（query），连接（connect）
state    #显示当前sql语句的状态
系统分配的"connection_id"，可以使用函数connection_id()查看

一个对象若只剩下弱引用，则该对象在GC时就会被回收
强引用
垃圾回收机制绝不会回收它，即使内存不足时，JVM宁愿抛出OutOfMemoryError错误，
使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。

软引用
Object obj = new Object();
SoftReference sf = new SoftReference(obj);
这里sf是对obj的一个软引用，
如果内存空间足够，垃圾回收机制就不会回收它。

弱引用
Object obj = new Object();
WeakReference wf = new WeakReference(obj);
在垃圾回收器线程扫描它 所管辖的内存区域的过程中，
一旦发现具有弱引用的对象，不管内存是否充足，都会被回收。
可以作为缓存

虚引用
String str=new String("abc");
ReferenceQueue queue=new ReferenceQueue();
PhantomReference ref=new PhantomReference(str,queue);
垃圾回收机制在回收对象时，如果发现还有虚引用，
就会在回收对象之前，把这个虚引用加入到与之关联的引用队列中。

如果一个ThreadLocal没有外部强引用来引用它，比如将ThreadLocal A 这个对象赋值为null，那么系统GC时ThreadLocal A 势必
会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，Java程序没有办法访问key为null的Entry的value,
如果当前线程迟迟不结束的话，如线程池，那么这些key为null的Entry的value就会一直存在一条强引用链

避免内存泄露的最好的做法是主动调用ThreadLocal对象的remove方法，将ThreadLocal对象中的值删除
在set get方法时会清除ThreadLocalMap中key为null的value

@Transactional注解失效  应该抛出非检查性异常
下单method1，减库存method2，method2中检查下库存，如果库存不足抛出new Exception()
但是Transactional注解只是捕获   非检查性异常   才会回滚，对于检查性异常不会进行任何操作
解决办法就是抛出非检查性异常

但是如果必须抛出检查性异常，也期望回滚，也是可以的，只需要将注解的
@Transactional(rollbackFor=Exception.class)

Java中所有不是RuntimeException派生的Exception都是检查型异常
检查型异常是JAVA首创的，在编译期对异常的处理有强制性的要求。
在JDK代码中大量的异常属于检查型异常，包括IOException，SQLException, FileNotFoundException等等。

在Java中所有RuntimeException的派生类都是非检查型异常，
与检查型异常对比，非检查型异常可以不在函数声明中添加throws语句，调用函数上也不需要强制处理。
常见的NullPointException，ClassCastException是常见的非检查型异常。
非检查型异常可以不使用try...catch进行处理，但是如果有异常产生，则异常将由JVM进行处理。
对于RuntimeException的子类最好也使用异常处理机制。
虽然RuntimeException的异常可以不使用try...catch进行处理，但是如果一旦发生异常，则肯定会导致程序中断执行，
所以，为了保证程序再出错后依然可以执行，在开发代码时最好使用try...catch的异常处理机制进行处理。

放调用getUser时，只打印了getUser，没有打印getAddress，AOP没有如期实现，前后打印日志的功能 代理模式
@MethodLog
public User getUser(){
    getAddress()
    ...
}@MethodLog
public Address getAddress(){
    ...
}
代理类中定义方法，不会调用代理类的getAddress方法
解决办法，通过代理类调用getAddress方法就可以了

SimpleDateFormat 结果不是期望的
SimpleDateFormat大写YYYY是周年，这一周所在的年份  日期转字符串 20201229多出一年
小写yyyy才是这一天所在的年份

为什么Random不随机
0-25随机数
public static Integer randomNum() {
    Random random = new Random(1000);
    return random.nextInt(26);
}
不可重复调用该方法
解决方式，改为单例的：
static Random random = new Random(1000);
public static Integer randomNum() {
    return random.nextInt(26);
}

如何基于mysql的行锁实现悲观锁？
行锁作用：其他线程等待 同一时刻，只有一个线程能够修改记录的某些列
悲观锁：要修改行记录，获取行记录的锁，修改数据，更新DB，释放行锁，在这个过程中，其他人不能修改该行记录
试图修改该记录的请求会被阻塞到获取该记录行锁上 多线程改数据会出现数据被覆盖
接下来基于场景：
扣减库存：java代码要有原子性
如何用悲观锁保证多线程下更新库存值的正确性
1 查询库存 for update 其他线程会被阻塞
2 扣减对象库存
3 更新库存到数据库
这样能做到正确吗？其实不然  线程A（拿到100值）获取到的行锁在执行完步骤1后会被释放
而线程B在执行步骤1获取到行锁，查询的值仍是100
扩大行锁范围，开启事务，加上begin，commit
注意：开启事务获取的行锁，要等到事务提交或者回滚时才会被释放
悲观锁的体现：
1 where id = #{}
2 修改对象库存值
3 where id = #{}

死锁的问题：
产生，排查，解决或者避免
因为争夺多个资源造成线程相互等待
线程死锁的4个必要条件：
1互斥，资源1被持有后不能被其他线程持有
2持有并等待
3不可剥夺
4环路等待条件，资源的环形链

dump jvm 内存
jmap -dump:live,format=b,file=heap.hprof 27019

dump pid 为 3239 的 java 进程的线程栈到 bb.txt 文件
jstack  -F 3239 > bb.txt

JDK自带打印线程堆栈：
jstack pid
避免：资源有序分配 比较大小
多个线程按照相同的顺序获取资源

spring事务传播性的理解？
是什么？传播行为？如何工作？
当多个含有事务的方法嵌套调用时，多个方法处理事务的规则
开启新事务，都会回滚吗？

在Transactional上的propagation的值
7种处理方式
1 PROPAGATION_REQUIRED 默认事务传播行为，如果外层调用方法已经开启了事务那么当前方法就加入到外层事务
如果外层调用方没有开启事务，那么当前方法就会开启一个新的事务
这种传播行为可以保证多个嵌套的事务方法在同一个事务内执行，可以保证多个事务方法同时提交或者回滚
@Service
public class ServiceA {
    @Autowired
    private ServiceB serviceB;

    @Transactional(rollbackFor=Exception.class, propagation=PROPAGATION_REQUIRED)
    public void methodA() {
        insert();
        sout(op to db);
        serviceB.methodB();//methodB和methodA 一样，methodB开启了事务，methodA开启了事务，两个事务会合并到一个事务当中

    B如果抛出异常，都会回滚，如果A try了B则也会回滚事务，因为REQUIRED语义
    就是嵌套调用的多个事务方法在同一个事务内进行，只要有一个事务出现异常，就要回滚

2 PROPAGATION_REQUIRES_NEW 每次都开启一个事务
    如果外层调用方已经开启了事务，就先把外层的事务挂起，然后执行当前新事务
    执行完毕后再恢复上层事务的执行
    @Service
    public class ServiceB {
        @Transactional(rollbackFor=Exception.class, propagation=Requires_new)
        public void methodB() {
            insert()
            sout(db)
        }
    }

    @Service
    public class ServiceA {
        @Autowire
        private ServiceB serviceB;

        @Transactional(rollbackFor=Exception.class, propagation=Required)
        public void methodA() {}
            insert();
            sout(op to db)
            serviceB.methodB():
        }
    }  methodA开启一个事务1，由于methodB为new，会先挂起methodA开启的事务1，然后开启自己的事务2，
    再执行methodB，当methodB执行完后会先提交事务2，然后恢复对应的事务1的执行，最终提交事务1
    当methodB发生异常，2会回滚，当时methodA不受影响。

3 PROPAGATION_SUPPORTED 如果外层调用方开启了事务，那当前方法就加入到外层事务，
如果外层不存在事务，那么当前方法也不会创建新事务，直接使用非事务方式执行

4 PROPAGATION_NOT_SUPPORTED 不支持事务，相当于隔离

5 PROPAGATION_NEVER 不支持事务,如果外层事务开启了事务，执行标有该注解的当前方法前会抛出异常

6 PROPAGATION_MANDATORY 配置了这个传播性的方法只能在已存在事务的方法中被调用，
如果在不存在事务的方法中被调用，就会抛出异常

7 PROPAGATION_NESTED  避免所有嵌套事务回滚
Required方法A调用Nested方法B，会新建一个保存点，B使用了A的事务，methodB抛出异常时，methodB 的插入操作会
回滚，但是a的前边调用的方法不会回滚，因为执行B前建立了保存点，B的回滚只会回滚到这个保存点之前，B之后的A方法的
逻辑会继续走下去

是为了解决事务嵌套问题的
常用前两个，第一个保证多个事务方法在一个事务中执行，保证方法的原子性
第二个保证内层方法开启独立于外层方法的事务，当内层方法抛出异常回滚自己的事务时，不会影响外层事务方法的执行

你在自己负责维护的 MySQL 里看到很多个线程都处于“Sending to client”这个状态，
就意味着你要让业务开发同学优化查询结果，并评估这么多的返回结果是否合理。

“Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。
比如，你可以构造一个锁等待的场景，就能看到 Sending data 状态。

仅当一个线程处于“等待客户端接收结果”的状态，才会显示"Sending to client"；
而如果显示成“Sending data”，它的意思只是“正在执行”。现在你知道了，
查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。

Buffer Pool加速查询
因为这时候内存数据页的结果是最新的，直接读内存页就可以了。
你看，这时候查询根本不需要读磁盘，直接从内存拿结果，速度是很快的。
所以说，Buffer Pool 还有加速查询的作用。
而 Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率。

查看BP内存命中率
show engine innodb status : buffer pool hit rate

一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。

innodb_buffer_pool_size
InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，
一般建议设置成可用物理内存的 60%~80%。

innodb_buffer_pool_size 小于磁盘的数据量是很常见的。
如果一个 Buffer Pool 满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。
InnoDB 内存管理用的是最近最少使用
(Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。

t1驱动表
select * from t1 straight_join t2 on (t1.a=t2.a);

理解了 MySQL 执行 join 的两种算法，现在我们再来试着回答文章开头的两个问题。
第一个问题：能不能使用 join 语句？如果可以使用 Index Nested-Loop Join 算法，
也就是说可以用上被驱动表上的索引，其实是没问题的；
如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。
尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。
所以你在判断要不要使用 join 语句时，
就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。

第二个问题是：如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？
如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；
如果是 Block Nested-Loop Join 算法：在 join_buffer_size 足够大的时候，是一样的；
在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。
所以，这个问题的结论就是，总是应该使用小表做驱动表。

在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，
过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

NLJ Explain下，没用用index nested-loop 的全要优化

三元表达式，使用if...else...代替，三元表达式中，会把所有的变量转换成同一种类型，会抛出NPE

基础类型int转换为包装类Integer的过程中，会调用Integer.valueOf方法

ThreadLocal获取RequestContext的userId竟然有值，是因为是从线程池中获取的，使用完remove

type表示数据扫描类型：
all index range ref eq_ref const 执行效率依次提高
全表扫描 全所索引扫描 索引范围扫描 非唯一索引扫描 唯一索引扫描 结果只有一条的注解或唯一索引扫描
前两个尽量避免

索引失效的例子：
索引列上做了计算，函数，类型转换操作 like匹配使用了前缀匹配符%abc，字符串不加引号导致类型转换
对索引列使用 !=  < >= < <= or in isnull,  is not null
###查询过程需要扫描整个索引并回表，代价高于直接全表扫描
查询优化器判断

回表都是一行行搜索主键索引的
按照主键递增的顺序查询，更容易进行磁盘的顺序读，MRR Multi-Range-Read

因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，
对磁盘的读比较接近顺序读，能够提升读性能。这，就是 MRR 优化的设计思路。
此时，语句的执行流程变成了这样：根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
将 read_rnd_buffer 中的 id 进行递增排序；
排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。
这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。
如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。
之后继续找索引 a 的下个记录，并继续循环。

另外需要说明的是，如果你想要稳定地使用 MRR 优化的话，
需要设置set optimizer_switch="mrr_cost_based=off"。
（官方文档的说法，是现在的优化器策略，
判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）
Extra里会显示MRR

MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），
可以得到足够多的主键 id。
这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。

理解了 MRR 性能提升的原理，我们就能理解 MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法了。
这个 BKA 算法，其实就是对 NLJ 算法的优化。

内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。
这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。
除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。而临时表，可以使用各种引擎类型 。
如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。