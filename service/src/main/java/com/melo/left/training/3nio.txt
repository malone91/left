端口是什么？
用来区分通信的时候知道是哪个服务


单线程处理Socket
每个请求一个线程
固定大小线程池处理
 服务员线程

单线程处理Socket
每个请求一个线程
固定大小线程池处理

存在两种类型操作
CPU计算、业务处理
IO操作与等待/网络、磁盘、数据库

Socket通信模型
建立连接
开始通信
结束通信

建立服务端通信Socket
等待并接收连接请求

创建连接Socket并向服务端发起请求

接收请求后创建连接Socket

InputStream OutputStream

关闭Socket相关资源（服务端和客户端都有）

为什么创建比CPU核心数多的线程？
有Sleep操作，等待处理，不消耗CPU
加入创建的线程数只有核心的CPU数的话，那么线程是吃不饱的，CPU占用被释放了，没有别的线程来
接，这样CPU资源就浪费掉了。不是所有的线程都在忙或者干活，有些员工摸鱼，所以有更多的员工干事。

对于一个IO相关应用来说，通过网络访问读取本地文件再返回给客户端，
大部分CPU使用的非常少，等资源可能就被浪费了。
分工协调上下文切换，所以需要统筹，
GC并发收集的时候，不影响业务线程 并行处理的多一些

不仅面临CPU、线程的问题，还有数据来回复制的问题
用户空间、内核空间

线程的等待导致CPU使用率不高、创建更多的线程导致了竞争，底层Socket操作更复杂，有很多资源消耗，这
就涉及到IO的模型，通信模型

阻塞、非阻塞 是线程处理模式
同步、异步 是通信模式 线程要不要拦住

		阻塞		非阻塞
同步   阻塞IO模型   非阻塞IO模型
       IO复用模型   信号驱动IO模型
异步                异步IO模型

基本上都是同步的

发起者的线程和处理结果的线程不是一个线程
叫人去买东西，自己做自己的事情，同步非阻塞。两个线程在做，把结果告诉我，不是当前线程做，背后有异步的线程池去做
在发起的线程看来是同步操作，但是比以前快了，有其他线程在帮助做，future.get()

IO模型 01- 阻塞式BIO IO
一般通过在while(true)循环中服务端会调用accept()方法等待接受客户端的连接的方式监听请求，请求一旦接收到一个连接请求，
就可以建立通信套接字并在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行
完成，不过可以通过多线程来支持多个客户端的链接。
线程跟内核打交道，不是直接和网络
IO模型 02- 非阻塞IO
和阻塞IO类比内核会立即返回，返回后获得足够的CPU时间继续做其他的事情，用户进程第一个阶段不是阻塞的，
需要不断的主动轮询kernel数据好了没有，第二个阶段依然总是阻塞的
多了个看有没有准备好，其他的还是和阻塞没什么区别
IO模型 03- 多路复用
IO multiplexing 时间驱动，就是在单个线程里同时监控多个套接字，通过select或poll轮询所负责的所有socket，
当某个socket有数据到达了，就通知用户进程。
IO复用同非阻塞IO本质一样，不过利用了新的select系统调用，由内核来负责本来是请求进程该做的轮询操作。
看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才提高了效率。
进程先是阻塞在select/poll 上，再是阻塞在读操作的第二个阶段上。

select和poll的几大缺点
1、每次调用select都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
2、同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
3、select支持的文件描述符数量太小了，默认1024
还是性能不够高
select数组，poll链表

epoll react模型
1、内核与用户空间进程共享一块内存的buffer区，避免了来回复制的问题
2、通过回调解决遍历问题，红黑树，循环递归查找点的效率提高了，注册回调的机制 返回准备好了的
3、fd没有限制，可以支撑10万连接
不需要长期等待的过程

IO模型 04- 信号驱动IO  用的比较少
信号驱动IO与BIO/NIO最大的区别就在于，在IO执行的数据准备阶段，不会阻塞用户进程
如Linux网络编程的图，当用户进程需要等待数据的时候，会向内核发送一个信号，告诉内核我需要什么数据，然后用户进程就继续做别的事情了，
而当内核中的数据准备好之后，内核立马发给用户进程一个信号，说数据准备好了，用户进程收到信号之后，立马调用recvfrom区接收数据

01:25-01:40视频时间
线程池-->EDA-->SEDA分阶段事件驱动架构，多个事件驱动加线程池
线程池确缺点：并发能力有一个峰值，到了一个最佳值后系统吞吐量会减小，延迟会上升
事件驱动：异步处理、回调，发送事件，提高吞吐量
事件处理机制：更为好，把发起的线程变成一个事件传出去，真正处理业务的这个模块或者线程，处理完后会继续 系统更为平稳
发起一个新的事件，链表？发起者没有直接调用 bus ，guava中有一个类，EventBus
发起者接收到任务处理完的事件继续走，跟异步是有区别的
事件处理机制的事件拆分的特别碎，没有关联，只需要知道从哪里拿事件；
发起者和最后一步可以在一个线程中做，可控性更强

异步最后一步是在被调起方做

IO模型 05-异步式IO  Proactor
异步IO 真正实现了IO全流程的非阻塞。用户进程发出系统调用后立即返回，内核等待数据准备完成，然后将数据拷贝到
用户进程缓冲区，然后发送信号告诉用户进程IO操作执行完成
与SIGIO相比，一个是发送信号告诉用户进程数据准备完毕，一个是IO执行完毕 Windows的IOCP模型

epoll是Reactor

这几种模式发明的时间比较早

全流程处理IO的链给切割开
流式处理

netty支持NIO BIO Linux-epoll Windows-iocp 支持TCP HTTP UDP，做了通用的壳子，切换不同的组件
并发不大，BIO厉害

异步JDBC nodejs异步代码非常多

httpserver：netty springboot 搞出的server 无状态的
webserver：Tomcat web容器环境有要求：支持session，jsp
jboss：数据库连接放在了Jboss服务器的配置上
jsp就是servlet，例子代码叫service方法，jsp生成servlet文件，然后编译为class文件

手写网关

netty是一个异步的网络框架
websocket是二进制的

netty特性：高性能的协议服务器，高吞吐，低延迟，低开销，零拷贝，可扩容，松耦合：网络和业务逻辑分离，使用方便、可维护性好

mina
一些新的协议是基于UDP做的，变得可靠，比如QQ 交易所提供的api是udp，效率高

越偏底层的代码越不讲究
越通用越平庸
自定义参数选择用哪个，去平衡trade-off

分布式事务，都是靠时钟来保证的